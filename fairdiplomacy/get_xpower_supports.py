#!/usr/bin/env python

import argparse
import collections
import json
import glob
import os
import pydipcc
import fairdiplomacy.game
import pydipcc
import tabulate
import pprint
import joblib
import torch
from typing import Optional

from fairdiplomacy.models.consts import POWERS
from fairdiplomacy.game import Game


def compute_xpower_supports_from_saved(path, max_year=None, cf_agent=None):
    """Computes cross-power supports from a JSON file in fairdiplomacy saved game format."""
    with open(path) as f:
        try:
            j = json.load(f)
        except json.JSONDecodeError as e:
            raise type(e)(f"Error loading {path}: \n {e.message}")

    game = Game.from_saved_game_format(j)
    return compute_xpower_supports(
        game, max_year=max_year, cf_agent=cf_agent, name=os.path.basename(path)
    )


def compute_xpower_supports(
    game: Game,
    max_year: Optional[str] = None,
    cf_agent: Optional[fairdiplomacy.agents.base_agent.BaseAgent] = None,
    name: str = "",
):
    """Computes average cross-power supports for an entire game.

        Arguments:
        - game: a fairdiplomacy.Game object
        - max_year: If set, only compute cross-power supports up to this year.
        - cf_agent: If set, look at supports orders generated by `cf_agent`,  in the context of the game state
                    and game orders generated from the other powers.
        - name: a label for this game, returned in the output.

        Returns a dict of statistics for this game.
          s --> total number of support orders
          x --> number of support orders that are cross-power
          e --> number of cross-power support orders that "had an effect" (vs. a hold order for that unit)
        """

    num_supports, num_xpower, num_eff = 0, 0, 0
    for phase in game.get_phase_history():
        state = phase.state
        if state["name"][1:-1] == max_year:
            break
        loc_power = {
            unit.split()[1]: power for power, units in state["units"].items() for unit in units
        }
        if cf_agent is not None:
            cf_orders = cf_agent.get_orders_many_powers(
                Game.clone_from(game, up_to_phase=state["name"]), powers=POWERS
            )

        for power, power_orders in phase.orders.items():
            if cf_agent is not None:
                power_orders = cf_orders[power]

            for order in power_orders:
                order_tokens = order.split()
                is_support = (
                    len(order_tokens) >= 5
                    and order_tokens[2] == "S"
                    and order_tokens[3] in ("A", "F")
                )
                if not is_support:
                    continue
                num_supports += 1
                src = order_tokens[4]
                if src not in loc_power:
                    raise RuntimeError(f"{order}: {src} not in {loc_power}")
                if loc_power[src] == power:
                    continue
                num_xpower += 1

                cf_states = []
                for do_support in (False, True):
                    g_cf = Game.clone_from(game, up_to_phase=state["name"])
                    g_cf.set_orders(power, power_orders)

                    assert g_cf.get_state()["name"] == state["name"]
                    if not do_support:
                        hold_order = " ".join(order_tokens[:2] + ["H"])
                        g_cf.set_orders(power, [hold_order])

                    g_cf.process()
                    assert g_cf.get_state()["name"] != state["name"]
                    s = g_cf.get_state()
                    cf_states.append((s["name"], s["units"], s["retreats"]))

                if cf_states[0] != cf_states[1]:
                    num_eff += 1

    return {"name": name, "s": num_supports, "x": num_xpower, "e": num_eff}


def compute_xpower_statistics(paths, max_year=None, num_jobs=40, cf_agent=None):

    if num_jobs == 1 or cf_agent is not None:
        # if running with CF-agent, can't use multiple cores (bc of model)
        stats = [
            compute_xpower_supports_from_saved(path, max_year=max_year, cf_agent=cf_agent)
            for path in paths
        ]
    else:
        stats = joblib.Parallel(num_jobs)(
            joblib.delayed(compute_xpower_supports_from_saved)(
                path, max_year=max_year, cf_agent=cf_agent
            )
            for path in paths
        )

    print(
        tabulate.tabulate(
            [(s["name"], s["s"], s["x"], s["e"]) for s in stats[:10]],
            headers=("name", "supports", "xpower", "effective"),
        )
    )
    print("...\n")

    x_support_ratio = sum([s["x"] / s["s"] for s in stats if s["s"] > 0]) / len(
        [s for s in stats if s["s"] > 0]
    )
    eff_x_support_ratio = sum([s["e"] / s["x"] for s in stats if s["x"] > 0]) / len(
        [s for s in stats if s["x"] > 0]
    )

    print(
        f"{len(paths)} games; x_support= {x_support_ratio:.4f}  eff_x_support= {eff_x_support_ratio:.4f}"
    )


def get_game_paths(
    game_dir, metadata_path=None, metadata_filter=None, dataset_for_eval=None, max_games=None
):
    if metadata_path:
        with open(metadata_path) as mf:
            metadata = json.load(mf)
            if metadata_filter is not None:
                filter_lambda = eval(metadata_filter)
                game_ids = [k for k, g in metadata.items() if filter_lambda(g)]
                print(f"Selected {len(game_ids)} / {len(metadata)} games from metadata file.")
            else:
                game_ids = metadata.keys()

            if dataset_for_eval:
                train_cache, eval_cache = torch.load(dataset_for_eval)
                del train_cache
                game_ids = eval_cache.game_ids
                print(
                    f"Selected {len(game_ids)} / {len(metadata)} games from dataset cache eval set."
                )

            metadata_paths = [f"{game_dir}/game_{game_id}.json" for game_id in game_ids]
            paths = [p for p in metadata_paths if os.path.exists(p)]
            print(f"{len(paths)} / {len(metadata_paths)} from metadata exist.")
    else:
        # just use all the paths
        paths = glob.glob(f"{game_dir}/game*.json")
        assert len(paths) > 0

    # reduce the number of games if necessary
    if len(paths) > max_games:
        print(f"Sampling {max_games} from dataset of size {len(paths)}")
        paths = [paths[i] for i in torch.randperm(len(paths))[:max_games]]

    return paths


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("game_dir", help="Directory containing game.json files")
    parser.add_argument(
        "--max-games", type=int, default=1000000, help="Max # of games to evaluate"
    )
    parser.add_argument(
        "--max-year", help="Stop computing at this year (to avoid endless supports for draw",
    )
    parser.add_argument(
        "--metadata-path", help="Path to metadata file for games, allowing for filtering"
    )
    parser.add_argument(
        "--metadata-filter", help="Lambda function to filter games based on metadata"
    )
    parser.add_argument("--dataset-for-eval", help="Dataset cache to select eval game IDs")
    args = parser.parse_args()

    paths = get_game_paths(
        args.game_dir,
        metadata_path=args.metadata_path,
        metadata_filter=args.metadata_filter,
        dataset_for_eval=args.dataset_for_eval,
        max_games=args.max_games,
    )

    compute_xpower_statistics(paths, max_year=args.max_year)
