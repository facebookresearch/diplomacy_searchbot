// Format this file with clang after editing:
//   clang-format-8 conf/conf.proto -i
syntax = "proto2";
package fairdiplomacy;

message MilaSlAgent {
  // Optional. Softmax temperature
  optional float temperature = 1;
}

message RandomAgent {}

message DipnetAgent {
  // Required. Path to DipNet checkpoint.
  optional string model_path = 1;

  // Optional. Softmax temperature
  optional float temperature = 2;

  // Optional. Share of probability mass to keep for sampling.
  optional float top_p = 3 [default = 1.0];
}

message CFR1PAgent {
  // Path to DipNet checkpoint.
  optional string model_path = 1;

  // Size of rollout process pool
  optional uint32 n_rollout_procs = 2;

  // Number of postman server processes to launch
  optional uint32 n_server_procs = 3;

  // Distribute server processes over multiple GPUs
  optional uint32 n_gpu = 4;

  // Model server maximum batch size
  optional uint32 max_batch_size = 5;

  // Number of CFR iterations
  optional uint32 n_rollouts = 6;

  // Maximum rollout length heuristically evaluating the game
  optional uint32 max_rollout_length = 7;

  // If true, use model predicted final scores in heuristic evalauation
  // If false, use current SC counts after max_rollout_length steps
  optional bool use_predicted_final_scores = 8;

  // Number of order-sets (actions) to consider at each step in search code
  optional uint32 n_plausible_orders = 9;

  // Temperature used for rollouts
  optional float rollout_temperature = 10;

  // If true, set postman batch size and use wait_till_full
  optional bool postman_sync_batches = 11;

  // Optional host:port for model server
  optional string use_server_addr = 12;

  // CUDA device to use, if > 0
  optional int32 device = 13 [ default = -1 ];

  // Optional float 0 - 1 to mix in raw sum of squares ratio
  optional float mix_square_ratio_scoring = 14;

  // Optional, # of rollouts to run in parallel for each possible action
  optional uint32 average_n_rollouts = 15;

  // Optional. Nucleus ratio used for rollouts. During nucleus sampling only the
  // smallest subset of actions that has probability at least top_p is
  // considered. All other actions are never sampled.
  optional float rollout_top_p = 16;

  // Optional, limit number of actions to consider as a ratio of # units
  // # plausible actions = min(ceil(max_actions_units_ratio * #units), n_plausible_orders)
  optional float max_actions_units_ratio = 17 [ default = -1 ];

  // Optional, if True, sample from final iter instead of average iter
  optional bool use_final_iter = 18 [ default = true ];

  // Optional: separate model path to compute the value function
  optional string value_model_path = 19;

  // Optional host:port for value model server
  optional string use_value_server_addr = 20;

  optional uint32 plausible_orders_req_size = 21 [ default = 0 ];

  // Optional, if True, prune actions after 1/4 of the number of iters
  optional bool use_pruning = 22 [ default = false ];

  // Optional, if >0 then play BP strategy for this many iters
  optional int32 bp_iters = 23 [ default = 0 ];

  // Optional, if >0 then play BP strategy for this many iters
  optional float bp_prob = 24 [ default = 0 ];

  // Optional, if >0, then at each rollout step will use the current
  // model-predicted value as this fraction of the final estimate
  // (i.e. exponentially decaying effect of rollouts of increasing length)
  optional float rollout_value_frac = 25 [ default = 0 ];

  optional bool cache_rollout_results = 26 [ default = false ];
}

message BRSearchAgent {
  // Path to DipNet checkpoint.
  optional string model_path = 1;

  // Size of rollout process pool
  optional uint32 n_rollout_procs = 2;

  // Number of postman server processes to launch
  optional uint32 n_server_procs = 3;

  // Distribute server processes over multiple GPUs
  optional uint32 n_gpu = 4;

  // Model server maximum batch size
  optional uint32 max_batch_size = 5;

  // Number of rollouts per plausible order
  optional uint32 rollouts_per_plausible_order = 6;

  // Maximum rollout length heuristically evaluating the game
  optional uint32 max_rollout_length = 7;

  // If true, use model predicted final scores in heuristic evalauation
  // If false, use current SC counts after max_rollout_length steps
  optional bool use_predicted_final_scores = 8;

  // Number of order-sets (actions) to consider at each step in search code
  optional uint32 n_plausible_orders = 9;

  // Temperature used for rollouts
  optional float rollout_temperature = 10;
}

message CE1PAgent {
  // Path to DipNet checkpoint.
  optional string model_path = 1;

  // Size of rollout process pool
  optional uint32 n_rollout_procs = 2;

  // Number of postman server processes to launch
  optional uint32 n_server_procs = 3;

  // Distribute server processes over multiple GPUs
  optional uint32 n_gpu = 4;

  // Model server maximum batch size
  optional uint32 max_batch_size = 5;

  // Number of CFR iterations
  optional uint32 n_rollouts = 6;

  // Maximum rollout length heuristically evaluating the game
  optional uint32 max_rollout_length = 7;

  // If true, use model predicted final scores in heuristic evalauation
  // If false, use current SC counts after max_rollout_length steps
  optional bool use_predicted_final_scores = 8;

  // Number of order-sets (actions) to consider at each step in search code
  optional uint32 n_plausible_orders = 9;

  // Temperature used for rollouts
  optional float rollout_temperature = 10;
}

message FP1PAgent {
  // Path to DipNet checkpoint.
  optional string model_path = 1;

  // Size of rollout process pool
  optional uint32 n_rollout_procs = 2;

  // Number of postman server processes to launch
  optional uint32 n_server_procs = 3;

  // Distribute server processes over multiple GPUs
  optional uint32 n_gpu = 4;

  // Model server maximum batch size
  optional uint32 max_batch_size = 5;

  // Number of CFR iterations
  optional uint32 n_rollouts = 6;

  // Maximum rollout length heuristically evaluating the game
  optional uint32 max_rollout_length = 7;

  // If true, use model predicted final scores in heuristic evalauation
  // If false, use current SC counts after max_rollout_length steps
  optional bool use_predicted_final_scores = 8;

  // Number of order-sets (actions) to consider at each step in search code
  optional uint32 n_plausible_orders = 9;

  // Temperature used for rollouts
  optional float rollout_temperature = 10;

  // If true, set postman batch size and use wait_till_full
  optional bool postman_sync_batches = 11;

  // Optional host:port for model server
  optional string use_server_addr = 12;

  // CUDA device to use, if > 0
  optional int32 device = 13 [ default = -1 ];

  // Optional float 0 - 1 to mix in raw sum of squares ratio
  optional float mix_square_ratio_scoring = 14;

  // Optional, # of rollouts to run in parallel for each possible action
  optional uint32 average_n_rollouts = 15;

  // Optional. Nucleus ratio used for rollouts. During nucleus sampling only the
  // smallest subset of actions that has probability at least top_p is
  // considered. All other actions are never sampled.
  optional float rollout_top_p = 16;

  // Optional, limit number of actions to consider as a ratio of # units
  // # plausible actions = min(ceil(max_actions_units_ratio * #units), n_plausible_orders)
  optional float max_actions_units_ratio = 17 [ default = -1 ];

  // Optional, if True, sample from final iter instead of average iter
  optional bool use_final_iter = 18 [ default = true ];

  // Optional: separate model path to compute the value function
  optional string value_model_path = 19;

  // Optional host:port for value model server
  optional string use_value_server_addr = 20;

  optional uint32 plausible_orders_req_size = 21 [ default = 0 ];

  // Optional, if True, prune actions after 1/4 of the number of iters
  // optional bool use_pruning = 22 [ default = false ];

  // Optional, if >0 then play BP strategy for this many iters
  optional int32 bp_iters = 23 [ default = 0 ];

  // Optional, if >0 then play BP strategy for this many iters
  optional float bp_prob = 24 [ default = 0 ];

  // Optional, if >0, then at each rollout step will use the current
  // model-predicted value as this fraction of the final estimate
  // (i.e. exponentially decaying effect of rollouts of increasing length)
  optional float rollout_value_frac = 25 [ default = 0 ];

  // Optional. If >0 then cache results after averaging results
  // for a set of orders this many times
  optional uint32 cache_rollout_results = 26 [ default = 0 ];
}

message ReproAgent {
    // Required, path to game.json file
    optional string game_path = 1;
}

message Agent {
  oneof agent {
    MilaSlAgent mila = 1;
    RandomAgent random = 2;
    DipnetAgent dipnet = 3;
    CFR1PAgent cfr1p = 4;
    BRSearchAgent br_search = 5;
    CE1PAgent ce1p = 6;
    ReproAgent repro = 7;
    FP1PAgent fp1p = 8;
  }
}

// Launcher message defines how to launch the job. Two options are avilable -
// locally or on slurm. Launcher information is expected to be a part of the
// main config.
message Launcher {

  message Local { optional bool use_local = 1; }

  message Slurm {
    optional int32 num_gpus = 1 [ default = 0 ];
    // By default starting one task per GPU. But if this flag is set, then
    // will use one task per machine.
    optional bool single_task_per_node = 2 [ default = false ];

    optional string partition = 3 [ default = "learnfair" ];

    optional int32 hours = 4;
    // Memory per GPU in GB.
    optional int32 mem_per_gpu = 5 [ default = 62 ];
    optional string comment = 6;

    // Number of CPUs per GPU. You probably want 40 on Pascals and 10 otherwise.
    optional int32 cpus_per_gpu = 7 [ default = 10 ];

    // If set, will schedule job only on volta GPUs with 32GB of mem.
    optional bool volta32 = 8;
    // If set, will schedule the job only on Pascal GPUs.
    optional bool pascal = 9;
    // If set, will schedule job only on volta GPUs.
    optional bool volta = 10;
  }

  oneof launcher {
    Local local = 1;
    Slurm slurm = 2;
  }
}

// Root config to compare agents.
message CompareAgentsTask {
  // The order here is expected to match fairdiplomacy.models.consts.POWERS
  enum Power {
    AUSTRIA = 0;
    ENGLAND = 1;
    FRANCE = 2;
    GERMANY = 3;
    ITALY = 4;
    RUSSIA = 5;
    TURKEY = 6;
  }

  optional Agent agent_one = 2;
  optional Agent agent_six = 3;
  optional Agent cf_agent = 4;

  optional Power power_one = 5;

  optional string out = 6;
  optional int32 seed = 7 [ default = 0 ];

  optional int32 num_processes = 90 [ default = 0 ];  // for data collection only!
  optional int32 num_trials = 91 [ default = 0 ];  // for data collection only!
  optional Launcher launcher = 100;
}

message TrainTask {
  // Path to dir containing game.json files.
  optional string data_dir = 1;

  // Path to dir containing dataset cache.
  optional string data_cache = 2;

  // Dataloader procs (1 means load in the main process).
  optional int32 num_dataloader_workers = 3;

  // Batch size per GPU.
  optional int32 batch_size = 4;

  // Learning rate.
  optional float lr = 5;

  // Learning rate decay per epoch.
  optional float lr_decay = 6;

  // Max gradient norm.
  optional float clip_grad_norm = 7;

  // Path to load/save the model.
  optional string checkpoint = 8;

  // Lercentage of games to use as val set.
  optional float val_set_pct = 9;

  // Prob[teacher forcing] during training.
  optional float teacher_force = 10;

  // LSTM dropout pct.
  optional float lstm_dropout = 11;

  // Encoder dropout pct.
  optional float encoder_dropout = 12;

  // If set, restrict data to S1901M.
  optional bool debug_only_opening_phase = 13;

  // If set, use a single process.
  optional bool debug_no_mp = 14;

  // Skip validation / save.
  optional bool skip_validation = 15;

  // Learn adjacency matrix.
  optional bool learnable_A = 16;

  // Obsolete.
  optional bool fill_missing_orders = 17 [ default = false ];

  // Learn attention alignment matrix.
  optional bool learnable_alignments = 18;

  // Average across location embedding instead of using attention.
  optional bool avg_embedding = 19;

  // Number of GCN layers in the encoder
  optional int32 num_encoder_blocks = 20;

  // Max number of epochs to train
  optional int32 num_epochs = 21;

  // If set, will write a jsonl file with metrics in the current folder.
  optional bool write_jsonl = 22;

  // Weight of value loss relative to policy loss, between 0 and 1
  optional float value_loss_weight = 23;

  // Scale factor for initial value decoder weights
  optional float value_decoder_init_scale = 24;

  // Max gradient norm in value decoder params
  optional float value_decoder_clip_grad_norm = 25;

  // Minimal score (num SC) of the at the enf of the game needed to include the
  // power into the training set.
  optional int32 only_with_min_final_score = 26 [default = 7];

  // Value head dropout pct.
  optional float value_dropout = 27;

  // Factor used in exponential weighted average of sum of squares scores
  optional float value_decay_alpha = 28 [ default = 1.0 ];

  optional Launcher launcher = 1000;
}

message LaunchBotTask {
  // Agent cfg to play against
  optional Agent agent = 1;

  // Diplomacy server host
  optional string host = 2;

  // Diplomacy server port
  optional int32 port = 3;

  // Run every period (in seconds)
  optional uint32 period = 4;

  // Number of powers to manage on server
  optional uint32 buffer_size = 5;

  // If non-zero, # of model servers to launch and reuse
  optional uint32 reuse_model_servers = 6;

  // If specified, connect only to this game
  optional string game_id = 7;

  // If specified, connect only as this power
  optional string power = 8;

  optional Launcher launcher = 1000;
}

// A dummy task to use in tests.
message TestTask {
  message SubMessage { optional int32 subscalar = 1 [ default = -1 ]; }

  enum SomeEnum {
    ZERO = 0;
    ONE = 1;
  };

  optional float scalar = 1 [ default = -1 ];
  optional SubMessage sub = 2;
  optional SubMessage sub2 = 3;

  optional SomeEnum enum_value = 4 [ default = ZERO ];
}

message ExploitTask {
  // DipNet ckpt to initialize both blueprint and explout agents.
  optional string model_path = 1;

  // Weight of critic loss in total loss.
  optional float critic_weight = 2 [ default = 1.0 ];
  // Weight of entropy loss in total loss.
  optional float entropy_weight = 3 [ default = 0.0 ];

  // Reward discounting.
  optional float discounting = 7 [ default = 1.0 ];

  // Optional. If set, weights of the exploit agent will be randomly
  // initialized.
  optional bool reset_agent_weights = 8;

  message Optimizer {
    // Required. Learning rate for Adam.
    optional float lr = 1;
    // Optional (but highly recommended). Gradient clipping.
    optional float grad_clip = 2;
  }
  optional Optimizer optimizer = 4;

  message Rollout {
    // Required. Max number of steps to do in the rollout.
    optional int32 rollout_max_length = 1;

    // Optional. How many parallel games to batch within single rollout.
    optional int32 rollout_batch_size = 2 [ default = 1 ];

    // Optional. How many rollout proccesses to run.
    optional int32 num_rollout_processes = 4 [ default = 1 ];

    // Optional. If set, will save games with this stride.
    optional int32 dump_games_every = 5;

    // Optional. Max batch size in postman inference processes.
    optional int32 inference_batch_size = 6;

    // Optional. Wait at least this number of seconds before loading new model
    // in the inference worker. By default check before every forward.
    optional int32 inference_ckpt_sync_every = 14;

    // Required. The size of the produces batches. That what the training loop
    // will receive.
    optional int32 batch_size = 7;

    // Optional. How much adjancent batches overleave. Note that default value
    // (1) means that each action frame will be used exactly once as last item
    // in a batch is remove in impala.
    optional int32 batch_interleave_size = 8;

    // Optional. If set, the batches will concatenate rollouts until batch_size
    // is reached, instead of following it exactly.
    optional bool do_not_split_rollouts = 9;

    optional bool single_rollout_gpu = 11;
    optional int32 server_procs_per_gpu = 12 [ default = 1 ];

    message Reward {
      // Required. Name of the score metric from fairdiplomacy.utils.game_scoring.
      optional string score_name = 1;

      // Optional. Penalty for each move to encourage shorter games.
      optional float delay_penalty = 2;

      // Optional. If set, then the reward will be a difference between the
      // score before the action and after the action.
      optional bool differential_reward = 3;

      // Optional. Hacky way to hardcore alliances.
      // 0 -> no alliances
      // 1 -> FRA, ENG, GER vs all.
      // 2 -> FRA, ENG, GER, IT vs all.
      // 3 -> FRA, ENG, RUS vs all.
      optional int32 alliance_type = 4;
    }

    // Required. How to compute rewards.
    optional Reward reward = 10;

    // Optional. Whether do self plat instead of exploitability.
    optional bool selfplay = 13;

    // Required in selfplay. Number of rollout proccess to do eval rollouts
    // against the supervised model. These rollouts are ingored for training.
    // These workers are subtracted from num_rollout_processes.
    optional int32 num_eval_rollout_processes = 15;

    // Required. Temperature for the oponent agent.
    optional float blueprint_temperature = 16;

    // Optional. If set, will stop rollout once the explout agent/agents is out.
    optional bool fast_finish = 17;
  }

  optional Rollout rollout = 5;

  message Trainer {
    // Optional. By default = infinite.
    optional int32 max_epochs = 1;
    // Required. Number of updates per epoch.
    optional int32 epoch_size = 2;
    // Optional. Save checkpoint every so many iterations.
    optional int32 save_checkpoint_every = 3;
    // Optional. Communicate current ckpt to inference workers every so often.
    optional int32 save_sync_checkpoint_every = 4 [default = 1];
    // Optional. Debugging option. Stop updating model after this number of updates.
    optional int32 max_updates = 5 [default = 0];
    // Optional. If set, will train a model being in eval mode.
    optional bool train_as_eval = 6;
    optional bool train_encoder_as_eval = 7;
    optional bool train_decoder_as_eval = 8;
    // Run everything in eval mode except for batch norm modules. Essentially it
    // puts only dropout to eval mode.
    optional bool train_as_eval_but_batchnorm = 9;
  }

  optional Trainer trainer = 6;

  // Optional. If positive, will set random seed for torch on the main process.
  optional int32 seed = 9 [default = -1];

  // Arbitraty comment. Could use to make a "re" run for the same config and
  // changed code.
  optional string comment = 999;
  optional Launcher launcher = 1000;
}

message BuildDbCacheTask {

  // Required. Glob pattern to game.json files
  optional string glob = 1;

  // Required. Path to save db cache
  optional string out_path = 2;

  // Minimal score (num SC) of the at the end of the game needed to include the
  // power into the training set.
  optional uint32 only_with_min_final_score = 3 [default = 7];

  // Optional. If specified, use this agent's orders instead of the orders in
  // the game.json
  optional Agent cf_agent = 4;

  // Optional, only valid with cf_agent. If > 1, sample cf_agent multiple
  // times, saving each as a separate row in the db.
  optional uint32 n_cf_agent_samples = 5 [ default = 1 ];

  // Optional, # of parallel encoding processes. Default = #cpu
  optional int32 n_parallel_jobs = 6 [ default = -1 ];

}

// Root config to compare agents.
message SituationCheckTask {
  optional Agent agent = 1;
  optional string situation_json = 2;
  optional int32 seed = 3 [ default = 0 ];
  optional string selection = 4;
  optional Launcher launcher = 100;
}
// Every config is parsed as Cfg that is thin wrapper over actual config for the
// task. Config inlude. Handled by HH.
message Include {
  // It's expected that <conf_dir>/<path>.prototxt exists. HeyHi will try a
  // series of different conf_dir's. It's easier to give an example. Let
  // assume that path to meta config is conf/c01/conf.prototxt and the include
  // is {path:slurm, mount:launcher}. Then HeyHi will try the following paths:
  // {conf/c01,conf/common,conf/c01/launcher,conf/common/launcher}/slurm.prototxt.
  // Obviously, if mount is root, then the latter 2 paths are omitted.
  optional string path = 1;
  // Dot-separated path to where to include the include within the main config.
  optional string mount = 2;
}

// The root config. Every top-level prototxt must be a message of this type.
// User's code will recieve a specific task config after all includes and
// redefines are resolved.
message MetaCfg {
  repeated Include includes = 1;
  oneof task {
    CompareAgentsTask compare_agents = 101;
    TrainTask train = 102;
    LaunchBotTask launch_bot = 103;
    ExploitTask exploit = 104;
    BuildDbCacheTask build_db_cache = 105;
    SituationCheckTask situation_check = 106;
    // Dummy task to test heyhi.
    TestTask test = 999;
  }
}
